{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linhhq/aye/blob/main/Training_captcha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7esYsQhAKrsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40493a15-94cf-4478-84b5-b95a490a8373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cp: cannot stat '/content/drive/MyDrive/captcha/pngs.10000.zip': No such file or directory\n",
            "unzip:  cannot find or open pngs.zip, pngs.zip.zip or pngs.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "## Copy captcha dataset from Drive, unzip it.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp \"/content/drive/MyDrive/captcha/pngs.10000.zip\" /content/pngs.zip\n",
        "!unzip pngs.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaO4zDbuMb-j",
        "outputId": "2e5cdb27-7e44-4858-d13b-40b269225a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.8.2\n"
          ]
        }
      ],
      "source": [
        "## Import \n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "piLtJhoPMwYF",
        "outputId": "9a6befd0-9899-4fb7-932a-84cb8f02576b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images found:  10000\n",
            "Shape of image:  (40, 200, 3)\n",
            "Shape of image:  (40, 200, 3)\n",
            "Shape of image:  (40, 200, 3)\n",
            "Shape of image:  (40, 200, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unqiue charcaters in the whole dataset:  29\n",
            "Maximum length of any captcha:  6\n",
            "Characters present:  ['2', '3', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z']\n",
            "Total number of samples in the dataset:  10000\n",
            "Number of training samples:  9000\n",
            "Number of validation samples:  1000\n",
            "Number of training images:  (9000, 40, 200)\n",
            "Number of training labels:  (9000,)\n",
            "Number of validation images:  (1000, 40, 200)\n",
            "Number of validation labels:  (1000,)\n"
          ]
        }
      ],
      "source": [
        "## Split the data set to training data and test data\n",
        "\n",
        "\n",
        "# Path to the data directory\n",
        "data_dir = Path(\"pngs/\")\n",
        "\n",
        "# Get list of all the images\n",
        "images = list(data_dir.glob(\"*.png\"))\n",
        "print(\"Number of images found: \", len(images))\n",
        "\n",
        "\n",
        "# Let's take a look at some samples first. \n",
        "# Always look at your data!\n",
        "sample_images = images[:4]\n",
        "\n",
        "_,ax = plt.subplots(2,2, figsize=(5,3))\n",
        "for i in range(4):\n",
        "    img = cv2.imread(str(sample_images[i]))\n",
        "    print(\"Shape of image: \", img.shape)\n",
        "    ax[i//2, i%2].imshow(img)\n",
        "    ax[i//2, i%2].axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Store all the characters in a set\n",
        "characters = set()\n",
        "\n",
        "# A list to store the length of each captcha\n",
        "captcha_length = []\n",
        "\n",
        "# Store image-label info\n",
        "dataset = []\n",
        "\n",
        "# Iterate over the dataset and store the\n",
        "# information needed\n",
        "for img_path in images:\n",
        "    # 1. Get the label associated with each image\n",
        "    label = img_path.name.split(\".png\")[0]\n",
        "    # 2. Store the length of this cpatcha\n",
        "    captcha_length.append(len(label))\n",
        "    # 3. Store the image-label pair info\n",
        "    dataset.append((str(img_path), label))\n",
        "    \n",
        "    # 4. Store the characters present\n",
        "    for ch in label:\n",
        "        characters.add(ch)\n",
        "\n",
        "# Sort the characters        \n",
        "characters = sorted(characters)\n",
        "\n",
        "# Convert the dataset info into a dataframe\n",
        "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
        "\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"Number of unqiue charcaters in the whole dataset: \", len(characters))\n",
        "print(\"Maximum length of any captcha: \", max(Counter(captcha_length).keys()))\n",
        "print(\"Characters present: \", characters)\n",
        "print(\"Total number of samples in the dataset: \", len(dataset))\n",
        "dataset.head()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "training_data, validation_data = train_test_split(dataset, test_size=0.1, random_state=seed)\n",
        "\n",
        "training_data = training_data.reset_index(drop=True)\n",
        "validation_data = validation_data.reset_index(drop=True)\n",
        "\n",
        "print(\"Number of training samples: \", len(training_data))\n",
        "print(\"Number of validation samples: \", len(validation_data))\n",
        "\n",
        "\n",
        "\n",
        "# Map text to numeric labels \n",
        "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
        "\n",
        "# Map numeric labels to text\n",
        "labels_to_char = {val:key for key, val in char_to_labels.items()}\n",
        "\n",
        "\n",
        "\n",
        "# Sanity check for corrupted images\n",
        "def is_valid_captcha(captcha):\n",
        "    for ch in captcha:\n",
        "        if not ch in characters:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "# Store arrays in memory as it's not a muvh big dataset\n",
        "def generate_arrays(df, resize=True, img_height=40, img_width=200):\n",
        "    \"\"\"Generates image array and labels array from a dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe from which we want to read the data\n",
        "        resize (bool)    : whether to resize images or not\n",
        "        img_weidth (int): width of the resized images\n",
        "        img_height (int): height of the resized images\n",
        "        \n",
        "    Returns:\n",
        "        images (ndarray): grayscale images\n",
        "        labels (ndarray): corresponding encoded labels\n",
        "    \"\"\"\n",
        "    \n",
        "    num_items = len(df)\n",
        "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
        "    labels = [0]*num_items\n",
        "    \n",
        "    for i in range(num_items):\n",
        "        img = cv2.imread(df[\"img_path\"][i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        if resize: \n",
        "            img = cv2.resize(img, (img_width, img_height))\n",
        "        \n",
        "        img = (img/255.).astype(np.float32)\n",
        "        label = df[\"label\"][i]\n",
        "        \n",
        "        # Add only if it is a valid captcha\n",
        "        if is_valid_captcha(label):\n",
        "            images[i, :, :] = img\n",
        "            labels[i] = label\n",
        "    \n",
        "    return images, np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "# Build training data\n",
        "training_data, training_labels = generate_arrays(df=training_data)\n",
        "print(\"Number of training images: \", training_data.shape)\n",
        "print(\"Number of training labels: \", training_labels.shape)\n",
        "\n",
        "\n",
        "# Build validation data\n",
        "validation_data, validation_labels = generate_arrays(df=validation_data)\n",
        "print(\"Number of validation images: \", validation_data.shape)\n",
        "print(\"Number of validation labels: \", validation_labels.shape)\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Generates batches from a given dataset.\n",
        "    \n",
        "    Args:\n",
        "        data: training or validation data\n",
        "        labels: corresponding labels\n",
        "        char_map: dictionary mapping char to labels\n",
        "        batch_size: size of a single batch\n",
        "        img_width: width of the resized\n",
        "        img_height: height of the resized\n",
        "        downsample_factor: by what factor did the CNN downsample the images\n",
        "        max_length: maximum length of any captcha\n",
        "        shuffle: whether to shuffle data or not after each epoch\n",
        "    Returns:\n",
        "        batch_inputs: a dictionary containing batch inputs \n",
        "        batch_labels: a batch of corresponding labels \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 labels,\n",
        "                 char_map,\n",
        "                 batch_size=16,\n",
        "                 img_width=200,\n",
        "                 img_height=50,\n",
        "                 downsample_factor=4,\n",
        "                 max_length=5,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.char_map = char_map\n",
        "        self.batch_size = batch_size\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(data))    \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Get the next batch indices\n",
        "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        \n",
        "        # 2. This isn't necessary but it can help us save some memory\n",
        "        # as not all batches the last batch may not have elements\n",
        "        # equal to the batch_size \n",
        "        batch_len = len(curr_batch_idx)\n",
        "        \n",
        "        # 3. Instantiate batch arrays\n",
        "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1), dtype=np.float32)\n",
        "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
        "        input_length = np.ones((batch_len, 1), dtype=np.int64) * (self.img_width // self.downsample_factor - 2)\n",
        "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "        \n",
        "        \n",
        "        for j, idx in enumerate(curr_batch_idx):\n",
        "            # 1. Get the image and transpose it\n",
        "            img = self.data[idx].T\n",
        "            # 2. Add extra dimenison\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            # 3. Get the correpsonding label\n",
        "            text = self.labels[idx]\n",
        "            # 4. Include the pair only if the captcha is valid\n",
        "            if is_valid_captcha(text):\n",
        "                label = [self.char_map[ch] for ch in text]\n",
        "                batch_images[j] = img\n",
        "                batch_labels[j] = label\n",
        "                label_length[j] = len(text)\n",
        "        \n",
        "        batch_inputs = {\n",
        "                'input_data': batch_images,\n",
        "                'input_label': batch_labels,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length,\n",
        "                }\n",
        "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
        "        \n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "# Batch size for training and validation\n",
        "batch_size = 16\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width=200\n",
        "img_height=40 \n",
        "\n",
        "# Factor  by which the image is going to be downsampled\n",
        "# by the convolutional blocks\n",
        "downsample_factor=4\n",
        "\n",
        "# Maximum length of any captcha in the data\n",
        "max_length=6\n",
        "\n",
        "# Get a generator object for the training data\n",
        "train_data_generator = DataGenerator(data=training_data,\n",
        "                                     labels=training_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=True\n",
        "                                    )\n",
        "\n",
        "# Get a generator object for the validation data \n",
        "valid_data_generator = DataGenerator(data=validation_data,\n",
        "                                     labels=validation_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=False\n",
        "                                    )\n",
        "\n",
        "\n",
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred, input_length, label_length):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "        \n",
        "        # On test time, just return the computed loss\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(shape=(img_width, img_height, 1), name='input_data', dtype='float32')\n",
        "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
        "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
        "    \n",
        "    # First conv block\n",
        "    x = layers.Conv2D(32,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv1')(input_img)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
        "    \n",
        "    # Second conv block\n",
        "    x = layers.Conv2D(64,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv2')(x)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
        "    \n",
        "    # We have used two max pool with pool size and strides of 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing it to RNNs\n",
        "    new_shape = ((img_width // 4), (img_height // 4)*64)\n",
        "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
        "    x = layers.Dense(64, activation='relu', name='dense1')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    \n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(128,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.2))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.25))(x)\n",
        "    \n",
        "    # Predictions\n",
        "    x = layers.Dense(len(characters)+1,\n",
        "              activation='softmax', \n",
        "              name='dense2',\n",
        "              kernel_initializer='he_normal')(x)\n",
        "    \n",
        "    # Calculate CTC\n",
        "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
        "    \n",
        "    # Define the model\n",
        "    model = keras.models.Model(inputs=[input_img,\n",
        "                                       labels,\n",
        "                                       input_length,\n",
        "                                       label_length],\n",
        "                                outputs=output,\n",
        "                                name='ocr_model_v1')\n",
        "    \n",
        "    # Optimizer\n",
        "    sgd = keras.optimizers.SGD(learning_rate=0.002,\n",
        "                               decay=1e-6,\n",
        "                               momentum=0.9,\n",
        "                               nesterov=True,\n",
        "                               clipnorm=5)\n",
        "    \n",
        "    # Compile the model and return \n",
        "    model.compile(optimizer=sgd)\n",
        "    return model\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwQKwIgKM_Ha",
        "outputId": "4b67a3ab-0557-4836-db59-2d8302b9376c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model created OK\n",
            "Epoch 1/50\n",
            "563/563 [==============================] - 221s 375ms/step - loss: 22.3843 - val_loss: 21.3814\n",
            "Epoch 2/50\n",
            "563/563 [==============================] - 206s 367ms/step - loss: 21.3783 - val_loss: 21.3416\n",
            "Epoch 3/50\n",
            "563/563 [==============================] - 206s 366ms/step - loss: 21.3523 - val_loss: 21.2821\n",
            "Epoch 4/50\n",
            "563/563 [==============================] - 205s 364ms/step - loss: 21.3424 - val_loss: 21.4200\n",
            "Epoch 5/50\n",
            "563/563 [==============================] - 206s 365ms/step - loss: 21.2921 - val_loss: 21.2207\n",
            "Epoch 6/50\n",
            "563/563 [==============================] - 206s 367ms/step - loss: 21.2309 - val_loss: 21.1908\n",
            "Epoch 7/50\n",
            "563/563 [==============================] - 207s 367ms/step - loss: 21.2137 - val_loss: 21.1941\n",
            "Epoch 8/50\n",
            "563/563 [==============================] - 208s 370ms/step - loss: 21.1867 - val_loss: 21.0571\n",
            "Epoch 9/50\n",
            "563/563 [==============================] - 208s 370ms/step - loss: 20.2015 - val_loss: 18.9472\n",
            "Epoch 10/50\n",
            "563/563 [==============================] - 208s 369ms/step - loss: 18.1824 - val_loss: 17.0228\n",
            "Epoch 11/50\n",
            "563/563 [==============================] - 210s 373ms/step - loss: 16.5421 - val_loss: 15.5669\n",
            "Epoch 12/50\n",
            "563/563 [==============================] - 208s 369ms/step - loss: 15.1820 - val_loss: 14.1178\n",
            "Epoch 13/50\n",
            "563/563 [==============================] - 209s 370ms/step - loss: 13.8688 - val_loss: 12.3561\n",
            "Epoch 14/50\n",
            "563/563 [==============================] - 208s 370ms/step - loss: 11.6978 - val_loss: 9.5233\n",
            "Epoch 15/50\n",
            "563/563 [==============================] - 210s 372ms/step - loss: 9.3830 - val_loss: 7.6960\n",
            "Epoch 16/50\n",
            "120/563 [=====>........................] - ETA: 2:43 - loss: 8.2922"
          ]
        }
      ],
      "source": [
        "## Create model and training\n",
        "\n",
        "model = build_model()\n",
        "#model.summary()\n",
        "print(\"model created OK\")\n",
        "\n",
        "# Add early stopping\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                   patience=5,\n",
        "                                   restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data_generator,\n",
        "                    validation_data=valid_data_generator,\n",
        "                    epochs=50,\n",
        "                    callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM3c6MaMNhOP",
        "outputId": "678f1cf1-86a2-4afd-d6b2-3ec7b7e2ff4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground truth: 3MCETA \t Predicted: 3MCETA\n",
            "Ground truth: WQXHGV \t Predicted: WQXHGV\n",
            "Ground truth: XCTQP5 \t Predicted: XCTQP5\n",
            "Ground truth: 7N5WEH \t Predicted: 7N5WEH\n",
            "Ground truth: PZCBC8 \t Predicted: PZCBC8\n",
            "Ground truth: HWJCHC \t Predicted: HWJCHC\n",
            "Ground truth: 7RTG8D \t Predicted: 7RTG8D\n",
            "Ground truth: 3SBYCM \t Predicted: 3SBYCM\n",
            "Ground truth: ERVJDQ \t Predicted: ERVJDQ\n",
            "Ground truth: CJPAHY \t Predicted: CJPAHY\n",
            "Ground truth: JZREAQ \t Predicted: JZREAQ\n",
            "Ground truth: 9Z7Z7C \t Predicted: 9Z7Z7C\n",
            "Ground truth: SGAWFC \t Predicted: SGAWFC\n",
            "Ground truth: 6VHJFE \t Predicted: 6VHJFE\n",
            "Ground truth: T5HWVY \t Predicted: T5HWVY\n",
            "Ground truth: K6KC72 \t Predicted: K6KC72\n"
          ]
        }
      ],
      "source": [
        "## Test and verify data\n",
        "\n",
        "## Create a new model from the before model in the training\n",
        "prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n",
        "                                        model.get_layer(name='dense2').output)\n",
        "\n",
        "# A utility to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    pred = pred[:, :-2]\n",
        "    input_len = np.ones(pred.shape[0])*pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, \n",
        "                                        input_length=input_len,\n",
        "                                        greedy=True)[0][0]\n",
        "    \n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results.numpy():\n",
        "        outstr = ''\n",
        "        for c in res:\n",
        "            if c < len(characters) and c >=0:\n",
        "                outstr += labels_to_char[c]\n",
        "        output_text.append(outstr)\n",
        "    \n",
        "    # return final text results\n",
        "    return output_text\n",
        "\n",
        "#  Let's check results on some validation samples\n",
        "for p, (inp_value, _) in enumerate(valid_data_generator):\n",
        "    bs = inp_value['input_data'].shape[0]\n",
        "    X_data = inp_value['input_data']\n",
        "    labels = inp_value['input_label']\n",
        "    \n",
        "    preds = prediction_model.predict(X_data)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "    \n",
        "    orig_texts = []\n",
        "    for label in labels:\n",
        "        text = ''.join([labels_to_char[int(x)] for x in label])\n",
        "        orig_texts.append(text)\n",
        "        \n",
        "    for i in range(bs):\n",
        "        print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_sNGCLwNnQp",
        "outputId": "1b4fb82a-f13e-431d-cf2c-23f9457bb367"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clone model success\n",
            "copy file /content/final.captcha.20220911.10_000.h5 OK\n",
            "copy file /content/final.captcha.20220911.10_000.json OK\n"
          ]
        }
      ],
      "source": [
        "## save model to using after\n",
        "\n",
        "## Tao mot model moi tu model cu, sau do kiem tra\n",
        "prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n",
        "                                        model.get_layer(name='dense2').output)\n",
        "print(\"clone model success\")\n",
        "\n",
        "model_file_name = \"final.captcha.20220911.10_000\"\n",
        "model_file_path = \"/content/\" + model_file_name + \".h5\"\n",
        "model_info_path = \"/content/\" + model_file_name + \".json\"\n",
        "\n",
        "prediction_model.save(model_file_name + \".h5\")\n",
        "!cp $model_file_path \"/content/drive/MyDrive/\"\n",
        "\n",
        "print(\"copy file \" + model_file_path + \" OK\")\n",
        "\n",
        "import json\n",
        "\n",
        "objs = {\n",
        "    \"characters\" : characters,\n",
        "    \"char_to_labels\" : char_to_labels,\n",
        "    \"labels_to_char\" : labels_to_char\n",
        "}\n",
        "\n",
        "json_str = json.dumps(objs, indent=4)\n",
        "with open(model_file_name + \".json\", \"w\") as outfile:\n",
        "    outfile.write(json_str)\n",
        "!cp $model_info_path \"/content/drive/MyDrive/\"\n",
        "print(\"copy file \" + model_info_path + \" OK\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}